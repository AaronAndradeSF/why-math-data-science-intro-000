{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's take a step back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the supervised learning algorithms that we have looked at so far, we are chugging along by following our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Collect**: Gather and clean the relevant data\n",
    "* **Explore**: Explore the data\n",
    "* **Train**: Choose a statistical or machine learning model (ie. a tool or algorithm) and optimize the model for some criteria (eg. how well the model predicts our data)\n",
    "* **Predict**: Make predictions with the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned, for collecting and exploring the data we mainly use our Python skills and knowledge about the domain.  Training a model is more about machine learning.  \n",
    "\n",
    "In linear regression analysis, our model is a regression line.  We use it to **model** the real world relationship between our explanatory variable and our dependent variable.  How do we know what that *real world relationship* is?  Because this is supervised learning, it comes from our existing *actual* data.  So, in the example we've been using, the actual data we have is the revenue, and we train our model by developing a regression line that minimizes the difference between the actual data and what our model expects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This training step is where calculus comes in.  By training a model, we move along a loss function, and calculus can tell us where to move next to minimize the loss function.\n",
    "\n",
    "\n",
    "\n",
    "So training a model, loss functions, and calculus, don't just come into play with regression lines.  Many algorithms in machine learning have a loss function. As we change the model parameters, the cost associated with that model changes.  Calculus gives us an expectation how much the cost associated with a model changes as we update that model.  In general, calculus can tell us *the rate of change*. If we know how our cost function is changing, then we can use this knowledge as we change a parameter, to tell us how to change a parameter next.\n",
    "\n",
    "The slope of the line to our cost function shows how to update our regression line.  That slope tells us how much our cost is changing as we change a single parameter of our model, and indicates how to change that parameter to improve our cost.\n",
    "\n",
    "Now as our models become more complex and there are more levers to pull, having a technique that tells us how to change the model next becomes very powerful.\n",
    "\n",
    "### Summary\n",
    "\n",
    "So in summary:\n",
    "* We'll use other types of models beyond drawing a regression line.  \n",
    "* There will be loss functions.  \n",
    "* We will want adapt our model to minimize the output from our loss function.  \n",
    "* That is training our model.  \n",
    "* Calculus tells us how to update our ML model and the change in output that will occur as a result. \n",
    "\n",
    "So moving along that loss function to approach the minimum in a structured way requires math, and derivatives.  \n",
    "\n",
    "The sections that follow will take a deep dive into mathematics and that will underly our future machine learning techniques.  Taking this exploration will allow us to understand our current machine learning model of gradient descent, as well how we can train other machine learning models in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
